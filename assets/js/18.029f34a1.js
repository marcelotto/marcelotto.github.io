(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{233:function(t,a,s){"use strict";s.r(a);var n=s(2),e=Object(n.a)({},function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"rdf-data-structures"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rdf-data-structures","aria-hidden":"true"}},[t._v("#")]),t._v(" RDF data structures")]),t._v(" "),s("p",[t._v("RDF.ex provides various data structures for collections of statements:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Description")]),t._v(": a collection of triples about the same subject")]),t._v(" "),s("li",[s("code",[t._v("RDF.Graph")]),t._v(": a named collection of statements")]),t._v(" "),s("li",[s("code",[t._v("RDF.Dataset")]),t._v(':  a named collection of graphs, i.e. a collection of statements from different graphs; it may have multiple named graphs and at most one unnamed ("default") graph')])]),t._v(" "),s("p",[t._v("All of these structures have similar sets of functions and implement Elixirs "),s("code",[t._v("Enumerable")]),t._v(" and "),s("code",[t._v("Collectable")]),t._v(" protocol, Elixirs "),s("code",[t._v("Access")]),t._v(" behaviour and the "),s("code",[t._v("RDF.Data")]),t._v(" protocol of RDF.ex.")]),t._v(" "),s("h2",{attrs:{id:"construction"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#construction","aria-hidden":"true"}},[t._v("#")]),t._v(" Construction")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("new")]),t._v(" function of these data structures create new instances of the struct. "),s("code",[t._v("RDF.Description.new")]),t._v(" requires at least an IRI or blank node for the subject, while "),s("code",[t._v("RDF.Graph.new")]),t._v(" and "),s("code",[t._v("RDF.Dataset.new")]),t._v(" take an optional IRI for the name of the graph or dataset via the "),s("code",[t._v("name")]),t._v(" option.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("empty_description "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nempty_unnamed_graph "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new\nempty_named_graph   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nempty_unnamed_dataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new\nempty_named_dataset   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("As you can see, qualified terms from a vocabulary namespace can be given instead of an IRI and will be resolved automatically. This applies to all of the functions discussed below.")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("new")]),t._v(" functions can be called more shortly with the respective delegator functions "),s("code",[t._v("RDF.description")]),t._v(", "),s("code",[t._v("RDF.graph")]),t._v(" and "),s("code",[t._v("RDF.dataset")]),t._v(".")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("new")]),t._v(" functions also take optional initial data, which can be provided in various forms. Basically it takes the given data and hands it to the "),s("code",[t._v("add")]),t._v(" function with the newly created struct. One way support by the "),s("code",[t._v("new")]),t._v(" constructor of all three data structures is with the "),s("code",[t._v(":init")]),t._v(" option.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("description "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nunnamed_graph "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnamed_graph   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nunnamed_dataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnamed_dataset   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The value of the "),s("code",[t._v(":init")]),t._v(" option can also be a function (without args) which can return the data to be initialized in any form discussed in the next subsection.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token capture function"}},[t._v("&initializer_function/0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("On the "),s("code",[t._v("new")]),t._v(" constructors of "),s("code",[t._v("RDF.Graph")]),t._v(" and "),s("code",[t._v("RDF.Dataset")]),t._v(" the data can also be passed directly in order to support its use with the pipeline operator.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("This feature cannot be supported on "),s("code",[t._v("RDF.Description/new/2")]),t._v(" since the subject is mandatory. But this shouldn't be such a big limitation, since often times "),s("code",[t._v("RDF.Description")]),t._v("s are created with the Description DSL introduced "),s("router-link",{attrs:{to:"/rdf-ex/vocabularies.html#description-dsl"}},[t._v("here")]),t._v(".")],1),t._v(" "),s("div",{staticClass:"danger custom-block"},[s("p",[t._v("This form of passing the input data directly has one caveat: the input form of grouping multiple predicate-object pairs for a subject given as a vocabulary namespace term is not supported as it is indistinguishable from Keyword opts, eg. in this example the input won't be recognized correctly:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("For this reason the usage of the "),s("code",[t._v(":init")]),t._v(" option variant is the recommended way to populate the data structures on construction. Use the direct passing variant only when you want to call the constructors in a pipeline and are sure that input in this form won't occur.")]),t._v(" "),s("p",[t._v("A workaround if you really want to use this variant and can't exclude this form is to explicitly pass options:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("h2",{attrs:{id:"input-forms"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#input-forms","aria-hidden":"true"}},[t._v("#")]),t._v(" Input forms")]),t._v(" "),s("p",[t._v("In the last section we already encountered a couple of ways of how RDF statements can be provided as input to the "),s("code",[t._v("new/2")]),t._v(" functions. There are more ways and all of them are commonly supported on all functions taking input data. Let's look at them one by one.")]),t._v(" "),s("p",[t._v("Most basically, single triple and quad tuples can be provided. As with all supported forms, the elements must not be RDF terms directly, as long they are coercible as discussed in the previous section about "),s("a",{attrs:{href:"statements"}},[t._v("Statements")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("On the object position a list of objects can provided for multiple statements to the same subject and predicate.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Multiple predicate-object pairs to the same subject can be given via a two-element tuple of a subject and a list of predicate-object pairs. The object can also be a list in this form.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("The input data can also be given as a map.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("This nested map form for RDF statements however is only supported on "),s("code",[t._v("RDF.Graph")]),t._v(" and "),s("code",[t._v("RDF.Dataset")]),t._v(" functions. The "),s("code",[t._v("RDF.Description")]),t._v(" operating only on RDF statements about the same subject supports the map form only with the inner  map with the predicate-object pairs.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("RDF.Description")]),t._v(" functions also supports the initially mentioned tuple forms, but the subject must match the subject of the description. Additionally however they support also two-element tuples with just the predicate and object(s).")]),t._v(" "),s("p",[t._v("Naturally it's also possible to provide the statements in the RDF data structures themselves. However, for any of RDF data structure only the respective RDF data structure itself and the smaller ones are supported:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Dataset")]),t._v(" functions with input data support all three RDF data structures.")]),t._v(" "),s("li",[s("code",[t._v("RDF.Graph")]),t._v(" functions can only handle "),s("code",[t._v("RDF.Graph")]),t._v("s and "),s("code",[t._v("RDF.Description")]),t._v("s.")]),t._v(" "),s("li",[s("code",[t._v("RDF.Description")]),t._v(" only works with "),s("code",[t._v("RDF.Description")]),t._v("s themself. Unlike the other forms for input data however, the subject of an input description does not have to match the subject of the description on which the function is applied.")])]),t._v(" "),s("div",{staticClass:"warning custom-block"},[s("p",[t._v("One could expect that "),s("code",[t._v("RDF.Dataset")]),t._v(" would support an additional nesting with graph names at the outer level, but this is not the case. Supporting this would have been relatively costly, since it would require always checking the depth of the given input. But it's also actually not needed for most cases, since the "),s("code",[t._v("RDF.Dataset")]),t._v(" functions allow addressing the graph separately via the "),s("code",[t._v("graph")]),t._v(" option.")])]),t._v(" "),s("p",[t._v("The input can be further shortened with the use of "),s("code",[t._v("RDF.PropertyMap")]),t._v("s, which are bidirectional mappings from atoms to IRIs of properties. They can be created from keyword lists or maps of terms to IRIs via the "),s("code",[t._v("new/1")]),t._v(" function or its alias function "),s("code",[t._v("RDF.property_map/1")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PropertyMap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.w3.org/1999/02/22-rdf-syntax-ns#type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PropertyMap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":type")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1999")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("02")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("syntax"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("ns"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#type>}")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property_map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("foo:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("bar:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PropertyMap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":bar")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":foo")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("foo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("PropertyMaps can also be created from strict vocabulary namespaces, where term mappings are added for lowercased terms.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property_map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PropertyMap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":comment")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#comment>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":domain")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#domain>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":isDefinedBy")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#isDefinedBy>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":label")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#label>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":member")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#member>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":range")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#range>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":seeAlso")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#seeAlso>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":subClassOf")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#subClassOf>,")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":subPropertyOf")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("> ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#subPropertyOf>")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("All functions accepting input data support a "),s("code",[t._v(":context")]),t._v(" option for which you can either pass a "),s("code",[t._v("RDF.ProperyMap")]),t._v(" directly or one of the values from which a "),s("code",[t._v("RDF.ProperyMap")]),t._v(" can be created implicitly. If the "),s("code",[t._v(":context")]),t._v(" is defined you can use the atoms for the properties in any of the input forms.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("property_map "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property_map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("foo:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("foo:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bar"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("context:")]),t._v(" property_map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nRDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subClassOf:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Class"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("context:")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Finally, lists of all the mentioned forms are accepted as input on the RDF data structures.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p3:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h2",{attrs:{id:"adding-statements"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#adding-statements","aria-hidden":"true"}},[t._v("#")]),t._v(" Adding statements")]),t._v(" "),s("p",[t._v("RDF statements can be added to the data structures with various functions, all which support all of the input forms introduced in the last section. Let's first define some example data structures on which we can exemplify the differences of the different functions.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" description "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ;\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" graph "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("prefixes:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attribute variable"}},[t._v("@prefix")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":S")]),t._v("\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p1")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":O1")]),t._v(" ;\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p2")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":O2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("add/3")]),t._v(" functions of the RDF data structures merge the given statements with the existing ones.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("New"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("New"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ;\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("context:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attribute variable"}},[t._v("@prefix")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":S")]),t._v("\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p1")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":O")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":O1")]),t._v(" ;\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p2")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":O2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("put/3")]),t._v(" functions on the other hand overwrite existing statements, but behave differently in their overwriting behavior depending on the respective RDF data structure:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Description.put/3")]),t._v(" overwrites only statements with same subject and predicate.")]),t._v(" "),s("li",[s("code",[t._v("RDF.Graph.put/3")]),t._v(" and "),s("code",[t._v("RDF.Dataset.put/3")]),t._v(" both overwrite all statements with same subject.")])]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("New"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("New"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ;\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("New"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("context:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attribute variable"}},[t._v("@prefix")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":S")]),t._v("\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p1")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":New")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("If you want to add statements to an "),s("code",[t._v("RDF.Graph")]),t._v(" or "),s("code",[t._v("RDF.Dataset")]),t._v(" with the same overwrite behavior as "),s("code",[t._v("RDF.Description.put/3")]),t._v(", i.e. only overwrite the statements with the same subject and predicate, you can use the "),s("code",[t._v("RDF.Graph.put_properties/3")]),t._v(" and "),s("code",[t._v("RDF.Dataset.put_properties/3")]),t._v(" functions.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put_properties"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("New"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("context:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attribute variable"}},[t._v("@prefix")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":S")]),t._v("\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p1")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":New")]),t._v(" ;\n      ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p2")]),t._v(" ex"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":O2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("As mentioned in the last section, When the subject of a statement doesn't match the subject of a description, "),s("code",[t._v("RDF.Description.add/3")]),t._v(" ignores it and is a no-op, but when given a "),s("code",[t._v("RDF.Description")]),t._v(" to add it ignores its subject and just adds its property-value pairs, because this is a common use case when merging the descriptions of differently named resources.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" description "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Other"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Other"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("Since "),s("code",[t._v("put/3")]),t._v(" is a destructive operation, "),s("code",[t._v("RDF.Description.put/3")]),t._v(" does not replicate the behavior of "),s("code",[t._v("RDF.Description.add/3")]),t._v(" to ignore the subject of descriptions. If you really want to overwrite the statements of a description with the ones from another description with "),s("code",[t._v("put/3")]),t._v(" you'll have to explicitly change the subject of the input description with "),s("code",[t._v("RDF.Description.change_subject/2")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" other_description "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Other"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Other"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" other_description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("change_subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("other_description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("As most of the functions of "),s("code",[t._v("RDF.Dataset")]),t._v(" the functions for adding statements have essentially two modes in which they operate:")]),t._v(" "),s("ol",[s("li",[t._v("When called with a graph name via the "),s("code",[t._v(":graph")]),t._v(" option, the function call is essentially delegated to the respective graph and the implementation of this function on "),s("code",[t._v("RDF.Graph")]),t._v(", which might even mean that input data from different graphs (eg. quads or "),s("code",[t._v("RDF.Graph")]),t._v("s with different graph names) becomes aggregated and get redirected to the specified graph.")]),t._v(" "),s("li",[t._v("Without a "),s("code",[t._v(":graph")]),t._v(" option the all quads or "),s("code",[t._v("RDF.Graph")]),t._v("s in the input are directed to respective graphs.")])]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" dataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("graph_names:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("default_graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: ~I<http://example.com/Graph>")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graphs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: ~I<http://example.com/Graph>")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("graph:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graphs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"new"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: ~I<http://example.com/Graph>")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("p",[t._v("Unlike the "),s("code",[t._v("add")]),t._v(" function, which always returns the same data structure as the data structure to which the addition happens, which possible means ignoring some input statements (eg. when the subject of a statement doesn't match the description subject) or reinterpreting some parts of the input statement (eg. ignoring the subject of another description), the "),s("code",[t._v("merge")]),t._v(" function of the "),s("code",[t._v("RDF.Data")]),t._v(" protocol implemented by all three data structures will always add all of the input statements and possibly creates another type of data structure. For example, merging two "),s("code",[t._v("RDF.Description")]),t._v("s with different subjects results in a "),s("code",[t._v("RDF.Graph")]),t._v(" or adding a quad to a "),s("code",[t._v("RDF.Graph")]),t._v(" with a different name than the quads graph context results in a "),s("code",[t._v("RDF.Dataset")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("merge"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# returns an unnamed RDF.Graph")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("merge"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# returns a RDF.Dataset")]),t._v("\n")])])]),s("p",[t._v("Finally, the "),s("code",[t._v("update/4")]),t._v(" functions allows updating of specified elements in the RDF data structures with a custom update function based on the previous values.")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Description.update/4")]),t._v(" updates the objects of the given predicate with the results of the update function which receives the previous objects and can either return a single or multiple new objects to be set or "),s("code",[t._v("nil")]),t._v(" if all statements with this predicate should be deleted.")]),t._v(" "),s("li",[s("code",[t._v("RDF.Graph.update/4")]),t._v(" updates the description of the given subject with the results of the update function which receives the previous "),s("code",[t._v("RDF.Description")]),t._v(" and can either return all supported input formats for "),s("code",[t._v("RDF.Description")]),t._v("s or "),s("code",[t._v("nil")]),t._v(" if the description should be deleted.")])]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">      XSD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("object"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("43")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" description "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Graph<name: nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("The optional third argument allows to specify a default value which should be set in case no value to be updated exist for the given element.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2 "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("h2",{attrs:{id:"accessing-the-content"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#accessing-the-content","aria-hidden":"true"}},[t._v("#")]),t._v(" Accessing the content")]),t._v(" "),s("p",[t._v("All three RDF data structures implement the "),s("code",[t._v("Enumerable")]),t._v(" protocol over the set of contained statements. In the case of "),s("code",[t._v("RDF.Description")]),t._v(" and "),s("code",[t._v("RDF.Graph")]),t._v(" as a set of triples and in case of "),s("code",[t._v("RDF.Dataset")]),t._v(" as a set of quads. This means you can use all "),s("code",[t._v("Enum")]),t._v(" functions over the contained statements as tuples.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" Enum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("each"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token capture function"}},[t._v("&IO.inspect/1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("RDF.Data")]),t._v(" protocol offers various functions to access the contents of RDF data structures:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Data.subjects/1")]),t._v(" returns the set of all subject resources")]),t._v(" "),s("li",[s("code",[t._v("RDF.Data.predicates/1")]),t._v(" returns the set of all used properties")]),t._v(" "),s("li",[s("code",[t._v("RDF.Data.objects/1")]),t._v(" returns the set of all resources on the object position of statements - literals not included")]),t._v(" "),s("li",[s("code",[t._v("RDF.Data.resources/1")]),t._v(" returns the set of all used resources at any position in the contained RDF statements")]),t._v(" "),s("li",[s("code",[t._v("RDF.Data.description/2")]),t._v(" returns all statements from a data structure about the given resource as a "),s("code",[t._v("RDF.Description")]),t._v(". It will be empty if no such statements exist. On a "),s("code",[t._v("RDF.Dataset")]),t._v(" it will aggregate the statements about the resource from all graphs.")]),t._v(" "),s("li",[s("code",[t._v("RDF.Data.descriptions/1")]),t._v(" returns all "),s("code",[t._v("RDF.Description")]),t._v("s within a data structure (possible aggregated in the case of a "),s("code",[t._v("RDF.Dataset")]),t._v(")")]),t._v(" "),s("li",[s("code",[t._v("RDF.Data.statements/1")]),t._v(" returns a list of all contained RDF statements")])]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("get/3")]),t._v(" functions return individual elements of a RDF data structure:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Description.get/3")]),t._v(" returns the list of all object values for a given property")]),t._v(" "),s("li",[s("code",[t._v("RDF.Graph.get/3")]),t._v(" returns the "),s("code",[t._v("RDF.Description")]),t._v(" for a given subject resource")]),t._v(" "),s("li",[s("code",[t._v("RDF.Dataset.get/3")]),t._v(" returns the "),s("code",[t._v("RDF.Graph")]),t._v(" with the given graph name")])]),t._v(" "),s("p",[t._v("All of these "),s("code",[t._v("get/3")]),t._v(" functions return "),s("code",[t._v("nil")]),t._v(" or the optionally given default value, when the given element cannot be found.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":not_found")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":not_found")]),t._v("\n")])])]),s("p",[t._v("You can get a single object value for a given predicate in a "),s("code",[t._v("RDF.Description")]),t._v(" with the "),s("code",[t._v("RDF.Description.first/2")]),t._v(" function:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("Since all three RDF data structures implement the "),s("code",[t._v("Access")]),t._v(" behaviour, you can also use "),s("code",[t._v("data[key]")]),t._v(" syntax, which basically just calls the respective "),s("code",[t._v("get")]),t._v(" function.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n")])])]),s("p",[t._v("Also, the familiar "),s("code",[t._v("fetch/2")]),t._v(" function of the "),s("code",[t._v("Access")]),t._v(" behaviour, as a variant of "),s("code",[t._v("get/3")]),t._v(" which returns "),s("code",[t._v("ok")]),t._v(" tuples, is available on all RDF data structures.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":error")]),t._v("\n")])])]),s("p",[s("code",[t._v("RDF.Dataset")]),t._v(" also provides the following functions to access individual graphs:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Dataset.graphs/1")]),t._v(" returns the list of all the graphs of the dataset")]),t._v(" "),s("li",[s("code",[t._v("RDF.Dataset.default_graph/1")]),t._v(" returns the default graph of the dataset")]),t._v(" "),s("li",[s("code",[t._v("RDF.Dataset.graph/2")]),t._v(" returns the graph of the dataset with the given name")])]),t._v(" "),s("h2",{attrs:{id:"querying-graphs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#querying-graphs","aria-hidden":"true"}},[t._v("#")]),t._v(" Querying graphs")]),t._v(" "),s("p",[t._v("The SPARQL.ex package allows you to execute SPARQL queries against RDF.ex graphs. It's still very limited at the moment. See the "),s("a",{attrs:{href:"/sparql-ex"}},[t._v("SPARQL.ex guide")]),t._v(" for more information. But you can also do basic graph queries within RDF.ex directly with the "),s("code",[t._v("RDF.Graph.query/3")]),t._v(" or "),s("code",[t._v("RDF.Graph.query_stream/3")]),t._v(" functions.")]),t._v(" "),s("p",[t._v("These functions take a graph and a basic graph pattern (BGP) consisting of some RDF triples with variables, which are written as atoms ending with a question mark. The RDF triples with the variables can again provided in any of the forms for input data introduced above. This query for example returns all triples about resources which have a "),s("code",[t._v('rdfs:label "foo"')]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":s")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":s")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":p")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":o")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The results are returned in an "),s("code",[t._v(":ok")]),t._v(" tuple (or directly with "),s("code",[t._v("RDF.Graph.query!/3")]),t._v(") as a list of solutions for the variables. The solutions are maps where the keys are the variables without the ending question mark.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("s:")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("subject"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p:")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#label>,")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("o:")]),t._v(" ~L"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Here's another example of a query pattern demonstrating one of the other forms and that also "),s("code",[t._v("RDF.PropertyMap")]),t._v("s can be used with the "),s("code",[t._v(":context")]),t._v(" opt:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  s?: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":o")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p2:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.14")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  o?: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p3:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bar"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("context:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p1:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p2:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("p3:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p3  \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("rdf:type")]),t._v(" property can be written shortly with the atom "),s("code",[t._v(":a")]),t._v(" and blank nodes can be written more shortly in the query pattern with atoms starting with an underscore.")]),t._v(" "),s("div",{staticClass:"tip custom-block"},[s("p",[t._v("Blank nodes in query patterns have the interesting property to behave like variables which don't show up in the results. So they can be quite convenient for intermediary variables.")])]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("_s:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">     "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":a")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Class"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">     RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),t._v("?\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" ~L"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("If you want store a basic graph pattern query in a variable for reuse or want to build your own query builder function you can use the "),s("code",[t._v("RDF.Query.bgp/2")]),t._v(" function. This function is used implicitly by "),s("code",[t._v("RDF.Graph.query/3")]),t._v(" to build "),s("code",[t._v("RDF.Query.BGP")]),t._v(" structs from lists (or tuples for single triple patterns).")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("query "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" \n  RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bgp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   s?: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":a")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Class"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),t._v("?\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nRDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("RDF.Query")]),t._v(" module also offers another handy builder function: "),s("code",[t._v("RDF.Query.path/2")]),t._v(" creates a basic graph pattern for a list representing a path through the graph.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("This is similar to the following query:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":_o")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":_o")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),t._v("?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("If you want the path builder function to generate variables (instead of blank nodes) for the path element objects in order to get them in the results, you can say so with the "),s("code",[t._v("with_elements: true")]),t._v(" option.")]),t._v(" "),s("p",[t._v("Instead of executing the query to get the results directly, you can also request the results as a stream with the "),s("code",[t._v("RDF.Graph.query_stream/3")]),t._v(" and "),s("code",[t._v("RDF.Graph.query_stream!/3")]),t._v(" functions.")]),t._v(" "),s("h2",{attrs:{id:"deleting-statements"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deleting-statements","aria-hidden":"true"}},[t._v("#")]),t._v(" Deleting statements")]),t._v(" "),s("p",[t._v("Statements can be deleted in two slightly different ways. One way is to use the "),s("code",[t._v("delete/3")]),t._v(" function of the respective data structure. It accepts all forms for specifying statements as input introduced above and removes the found triples.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("Another way to delete statements is the "),s("code",[t._v("delete/3")]),t._v(" function of the "),s("code",[t._v("RDF.Data")]),t._v(" protocol. The only difference to "),s("code",[t._v("delete")]),t._v(" functions on the data structures directly is how it handles the deletion of a "),s("code",[t._v("RDF.Description")]),t._v(" from another "),s("code",[t._v("RDF.Description")]),t._v(" or "),s("code",[t._v("RDF.Graph")]),t._v(" from another "),s("code",[t._v("RDF.Graph")]),t._v(". While the dedicated RDF data structure function ignores the description subject or graph name and removes the statements even when they don't match, "),s("code",[t._v("RDF.Data.delete/3")]),t._v(" only deletes when the descriptions subject respective graph name matches.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("S1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("O2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("Beyond that, there are:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("RDF.Description.delete_predicates/2")]),t._v(" which deletes all statements with the given property from a "),s("code",[t._v("RDF.Description")]),t._v(",")]),t._v(" "),s("li",[s("code",[t._v("RDF.Graph.delete_subjects/2")]),t._v(" which deletes all statements with the given subject resource from a "),s("code",[t._v("RDF.Graph")]),t._v(",")]),t._v(" "),s("li",[s("code",[t._v("RDF.Dataset.delete_graph/2")]),t._v(" which deletes all graphs with the given graph name from a "),s("code",[t._v("RDF.Dataset")]),t._v(" and")]),t._v(" "),s("li",[s("code",[t._v("RDF.Dataset.delete_default_graph/1")]),t._v(" which deletes the default graph of a "),s("code",[t._v("RDF.Dataset")]),t._v(".")])]),t._v(" "),s("h2",{attrs:{id:"equality"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#equality","aria-hidden":"true"}},[t._v("#")]),t._v(" Equality")]),t._v(" "),s("p",[t._v("RDF data structures can be compared for equality with the "),s("code",[t._v("equal?/2")]),t._v(" function of the respective data structure. You should these instead of comparisons with "),s("code",[t._v("==")]),t._v(", because the data structures might contain fields which are not relevant for equality. For example the defined prefixes (see "),s("a",{attrs:{href:"/../rdf-ex/serializations"}},[t._v("here")]),t._v(" for more on that) are ignored for this comparison.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("init:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("prefixes:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("prefixes:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("xsd:")]),t._v(" XSD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("> RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("prefixes:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v(">   RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("prefixes:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ex:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("xsd:")]),t._v(" XSD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n")])])]),s("p",[t._v("You can also compare different types of RDF data structures with the "),s("code",[t._v("RDF.Data.equal?/2")]),t._v(" function, which takes just the raw data into account.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n")])])]),s("p",[t._v("As opposed to "),s("code",[t._v("RDF.Graph.equal?/2")]),t._v(" the "),s("code",[t._v("RDF.Data.equal?/2")]),t._v(" function also doesn't consider the graph name when comparing "),s("code",[t._v("RDF.Graph")]),t._v("s.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal?"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n")])])])])},[],!1,null,null,null);a.default=e.exports}}]);