(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{209:function(t,a,s){"use strict";s.r(a);var n=s(2),e=Object(n.a)({},function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"lists"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#lists","aria-hidden":"true"}},[t._v("#")]),t._v(" Lists")]),t._v(" "),s("p",[t._v("RDF lists can be represented with the "),s("code",[t._v("RDF.List")]),t._v(" structure.")]),t._v(" "),s("p",[t._v("An existing "),s("code",[t._v("RDF.List")]),t._v(" in a given graph can be created with "),s("code",[t._v("RDF.List.new")]),t._v(" or its alias "),s("code",[t._v("RDF.list")]),t._v(", passing it the head node of a list and the graph containing the statements constituting the list.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("graph "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" \n  Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n     ~B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rest"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n     EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo\n     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rest"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nlist "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("List"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("~B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("If the given head node does not refer to a well-formed RDF list in the graph, "),s("code",[t._v("nil")]),t._v(" is returned.")]),t._v(" "),s("p",[t._v("An entirely new "),s("code",[t._v("RDF.List")]),t._v(" can be created with "),s("code",[t._v("RDF.List.from")]),t._v(" or "),s("code",[t._v("RDF.list")]),t._v(" and a native Elixir list or an Elixir "),s("code",[t._v("Enumerable")]),t._v(" with values of all types that are allowed for objects of statements (including nested lists).")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("list "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("If you want to add the graph statements to an existing graph, you can do that via the "),s("code",[t._v("graph")]),t._v(" option.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("existing_graph "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("O"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("graph:")]),t._v(" existing_graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("head")]),t._v(" option also allows to specify a custom node for the head of the list.")]),t._v(" "),s("p",[t._v("The function "),s("code",[t._v("RDF.List.values/1")]),t._v(" allows to get the values of a RDF list (including nested lists) as a native Elixir list.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("List"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("~L"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("ns"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("value:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2001")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("XMLSchema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#integer>},")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("value:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2001")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("XMLSchema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#integer>}]]")]),t._v("\n")])])])])},[],!1,null,null,null);a.default=e.exports}}]);