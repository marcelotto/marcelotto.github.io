(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{234:function(t,a,s){"use strict";s.r(a);var e=s(2),n=Object(e.a)({},function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"schemas"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#schemas","aria-hidden":"true"}},[t._v("#")]),t._v(" Schemas")]),t._v(" "),s("p",[t._v("A "),s("strong",[s("em",[t._v("Grax schema")])]),t._v(" is just an Elixir struct. In a traditional application, backed by a relational data model, you want to work with Elixir structs with the values from the relational database. You'll probably do this traditionally in Elixir with Ecto, by defining some "),s("code",[t._v("Ecto.Schema")]),t._v("s for the domain entities of your business. "),s("code",[t._v("Grax.Schema")]),t._v("s are similar to "),s("code",[t._v("Ecto.Schema")]),t._v("s, they both map the data to Elixir structs with some semantics on top of them, like a type system etc.")]),t._v(" "),s("p",[t._v("But while Ecto maps data from relational databases, Grax maps data from graph databases to Elixir structs. Graph databases are based on the graph data model, which has less technical friction between the conceptual model of the humans and the data model for the machine as it is perfectly "),s("a",{attrs:{href:"https://youtu.be/cHXbYLNa0qQ?t=290",target:"_blank",rel:"noopener noreferrer"}},[t._v("demonstrated here"),s("OutboundLink")],1),t._v(". By reducing the barrier between your conceptual models and the data models for your application, you have less to think about technical details and can spend more time on thinking about the actual domain model of the business problems your application has to solve.\nYou might have already got a feel of this, when working with GraphQL, where you simply define the nested schemas of a tree.")]),t._v(" "),s("p",[t._v("How does a "),s("code",[t._v("Grax.Schema")]),t._v(" definition look like? As an example, let's assume we have an RDF graph like this, which we want to map to Elixir structs with Elixir values for an Elixir application:")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('@prefix : <http://example.com/> .\n@prefix schema: <https://schema.org/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n\n:User1 \n    a schema:Person, :PremiumUser ;\n    schema:name "Jane" ;\n    schema:email "jane@example.com", "jane@work.com" ;\n    foaf:age 30 ;\n    schema:address [\n      schema:addressCountry "de"\n      schema:addressLocality "Berlin"\n    ] .\n\n:Post1\n    schema:name "Lorem" ;\n    schema:author :User1 ;\n    schema:articleBody """Lorem ipsum dolor sit amet, consectetur adipisicing elit. Provident, nihil, dignissimos. Nesciunt aut totam eius. Magnam quaerat modi vel sed, ipsam atque rem, eos vero ducimus beatae harum explicabo labore!""" .\n')])])]),s("p",[t._v("A Grax schema struct for the "),s("code",[t._v("User")]),t._v(" model of an application on this type of data could be defined with the "),s("code",[t._v("schema/1")]),t._v(" macro of the "),s("code",[t._v("Grax.Schema")]),t._v(" module like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("This will define a struct on the "),s("code",[t._v("User")]),t._v(" module. Although this struct doesn't have any user-defined fields for the domain model of our application yet, this could already represent an RDF graph node, since every "),s("code",[t._v("Grax.Schema")]),t._v(" struct has at least an internal "),s("code",[t._v("__id__")]),t._v("  field, which contains the "),s("code",[t._v("RDF.IRI")]),t._v(" or "),s("code",[t._v("RDF.BlankNode")]),t._v(", mapping to a graph node. So, an instance of this struct would look like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("EX\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("Address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" ~B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("Address1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("These structs from RDF.ex are the only RDF-related values you'll see in a Grax schema struct. The "),s("code",[t._v("__id__")]),t._v(" field should be treated similarly as the internal "),s("code",[t._v("__struct__")]),t._v(" field of Elixir structs: use it maybe for pattern matching, but don't touch it directly (other than via functions exposed by the API).")]),t._v(" "),s("div",{staticClass:"tip custom-block"},[s("p",[t._v("The "),s("code",[t._v("schema")]),t._v(" macro can be considered equal to a "),s("code",[t._v("defstruct")]),t._v(" in that it allows to define every struct which can be defined with it. Under the hood it will produce the "),s("code",[t._v("defstruct")]),t._v(" call as the first line of the generated code, which means you can use all types of annotations before the "),s("code",[t._v("schema")]),t._v(" macro that can be used before a "),s("code",[t._v("defstruct")]),t._v(", eg. "),s("code",[t._v("@derive")]),t._v(" annotations etc.")])]),t._v(" "),s("p",[t._v("But without any fields this isn't very interesting.")]),t._v(" "),s("h3",{attrs:{id:"properties"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#properties","aria-hidden":"true"}},[t._v("#")]),t._v(" Properties")]),t._v(" "),s("p",[t._v('As opposed to the term "field" used for the elements of Elixir structs and '),s("code",[t._v("Ecto.Schema")]),t._v("s, we are calling the elements of the "),s("code",[t._v("Grax.Schema")]),t._v(" struct "),s("strong",[s("em",[t._v("properties")])]),t._v(", because we're mapping them to RDF properties. Unlike for fields of an Ecto schema, we'll not just have to provide a name atom for our property fields, but also a URI for the RDF property.")]),t._v(" "),s("p",[t._v("So, a property definition on a Grax schema is done in the body of a "),s("code",[t._v("schema/1")]),t._v(" block with the "),s("code",[t._v("property/3")]),t._v(" macro and the property field name and a RDF property URI as the first two arguments.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("This will add an additional field on the Grax schema struct with the given name. The URI of the RDF property will be backed into the Grax schema struct. You won't have to deal with the URIs of the RDF properties furthermore. It will be automatically used for the mapping from and to RDF.")]),t._v(" "),s("p",[t._v("The URI can be given in any form the "),s("code",[t._v("RDF.IRI.new/1")]),t._v(" constructor of RDF.ex can create IRIs from, including IRIs directly (eg. via IRI sigils), strings or terms from an RDF.ex vocabulary namespace.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("div",{staticClass:"warning custom-block"},[s("p",[t._v("We'll constantly use terms from RDF.ex vocabulary namespaces. These are modules and functions on these modules, which can be used instead of URIs in the Elixir code. If you're new to RDF.ex, you can read more about this "),s("a",{attrs:{href:"/rdf-ex/vocabularies"}},[t._v("here")]),t._v(".")])]),t._v(" "),s("p",[t._v("You can also define properties in a more concise form with the "),s("code",[t._v("property/1")]),t._v(" macro:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Example "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("In this form the first keyword list element has this special meaning of a field name to property URI pair.")]),t._v(" "),s("p",[t._v("All of these definition forms lead to structs like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("The property is accessible as a usual field name of the struct, but has an exact RDF interpretation implicitly through the internal mapping to an RDF property identifier. These minimal forms without any further type specifications are already valid property definitions in Grax. Unlike an Ecto schema, where every field requires a type, for a Grax schema the types are optional, just as RDF and most other graph models are at its core schema-free data models with optional types later on.")]),t._v(" "),s("p",[t._v("But before we bring types into the game, we'll have to differentiate two general kinds of properties:")]),t._v(" "),s("ol",[s("li",[s("strong",[s("em",[t._v("Data properties")])]),t._v(", whose values we want to map to simple Elixir values, like strings and integers etc.")]),t._v(" "),s("li",[s("strong",[s("em",[t._v("Link properties")])]),t._v(" (the "),s("em",[t._v("object properties")]),t._v(" of OWL), whose IRI or blank node values should be mapped to recursively nested "),s("code",[t._v("Grax.Schema")]),t._v(" structs.")])]),t._v(" "),s("p",[t._v("Despite having very different kinds of values, there's one type dichotomy across both kinds of properties. We can have single values or sets of values.")]),t._v(" "),s("p",[t._v("By default it is assumed that the value of every property is unique, unless specified otherwise. If multiple values are allowed, a list type can be specified with the "),s("code",[t._v("list_of")]),t._v(" type constructor function, which expects the type of its elements. The values will then be kept in a list accordingly. If you want to specify that a property can have multiple values of any datatype you can use the "),s("code",[t._v("list")]),t._v(" function.")]),t._v(" "),s("p",[t._v("With that we can extend our example mapping schema like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":emails")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("Both email addresses from our example can now be represented in our "),s("code",[t._v("User")]),t._v(" struct:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@example.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@work.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("div",{staticClass:"warning custom-block"},[s("p",[t._v("Although ordered lists are used for multiple values, the order is irrelevant since the values have no particular order in RDF. You should not rely on any particalur order. Similarly, as the values are essentially sets, duplicates are not allowed. They will be removed automatically.")])]),t._v(" "),s("h2",{attrs:{id:"data-properties"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-properties","aria-hidden":"true"}},[t._v("#")]),t._v(" Data properties")]),t._v(" "),s("h3",{attrs:{id:"datatypes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#datatypes","aria-hidden":"true"}},[t._v("#")]),t._v(" Datatypes")]),t._v(" "),s("p",[t._v("The optional type specifications on our two kinds of properties are fundamentally different. The types of data properties defined with the "),s("code",[t._v("property")]),t._v(" macros can be specified by providing the name of a datatype with the "),s("code",[t._v(":type")]),t._v(" keyword.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":emails")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":age")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("The specified datatype defines what value a data property can have and which RDF datatype the produced literals for the RDF property should have.\nThe functions for working with these structs will validate these type definitions as described in the "),s("a",{attrs:{href:"/grax/api"}},[t._v("Grax API section")]),t._v(".")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("User")]),t._v(" structs now look like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@example.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@work.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("The types are given as atoms which correspond to the respective RDF.ex literal datatypes. Since RDF.ex implements the main parts of the XSD datatype system, a fairly rich set of types of values is type-derivation-aware available.")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("Grax datatype")]),t._v(" "),s("th",[t._v("RDF.ex literal datatype")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("code",[t._v(":any_uri")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.AnyURI")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":base64_binary")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Base64Binary")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":boolean")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Boolean")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":byte")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Byte")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":date")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Date")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":date_time")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.DateTime")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":decimal")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Decimal")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":double")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Double")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":float")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Float")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":int")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Int")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":integer")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Integer")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":long")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Long")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":negative_integer")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.NegativeInteger")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":non_negative_integer")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.NonNegativeInteger")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":non_positive_integer")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.NonPositiveInteger")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":positive_integer")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.PositiveInteger")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":short")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Short")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":string")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.String")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":time")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.Time")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":unsigned_byte")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.UnsignedByte")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":unsigned_int")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.UnsignedInt")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":unsigned_long")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.UnsignedLong")])])]),t._v(" "),s("tr",[s("td",[s("code",[t._v(":unsigned_short")])]),t._v(" "),s("td",[s("code",[t._v("RDF.XSD.UnsignedShort")])])])])]),t._v(" "),s("div",{staticClass:"warning custom-block"},[s("p",[t._v("The XSD date and time datatypes support also optional timezones, which are not supported by Elixir's "),s("code",[t._v("Date")]),t._v(" and "),s("code",[t._v("Time")]),t._v(" structs. Such date and time values with timezones are represented as tuples consisting of the "),s("code",[t._v("Date")]),t._v(" and "),s("code",[t._v("Time")]),t._v(" struct value and a string with the timezone, such as "),s("code",[t._v('{~D[2020-12-24], "+01:00"}')]),t._v(" or "),s("code",[t._v('{~T[00:00:00], "Z"}')]),t._v(".")])]),t._v(" "),s("p",[t._v("Above these there are a couple of special datatypes:")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("The "),s("code",[t._v(":any")]),t._v(" datatype is the default when no datatype is specified with the "),s("code",[t._v(":type")]),t._v(" keyword or is assumed for the the elements when using the "),s("code",[t._v("list")]),t._v(" type constructor function. It means the property can contain values of any datatype. The datatype mapping from Elixir values to XSD datatypes as described in "),s("router-link",{attrs:{to:"/rdf-ex/literals.html#typed-literals"}},[t._v("the table here")]),t._v(" is applied in this case.")],1)]),t._v(" "),s("li",[s("p",[t._v("The "),s("code",[t._v(":numeric")]),t._v(" datatype behaves similar to the "),s("code",[t._v(":any")]),t._v(" datatype, but limits the values to those of numeric datatypes.")])]),t._v(" "),s("li",[s("p",[t._v("The "),s("code",[t._v(":iri")]),t._v(" datatype can be used if IRIs should be kept as they are, which is useful when they shouldn't be mapped to nested mapping structs.")])])]),t._v(" "),s("h3",{attrs:{id:"default-values"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#default-values","aria-hidden":"true"}},[t._v("#")]),t._v(" Default values")]),t._v(" "),s("p",[t._v("Default values for the data properties can be defined with the "),s("code",[t._v(":default")]),t._v(" option. Its value is used as the default value of the Elixir struct.\nIf not specified otherwise, the default value will be "),s("code",[t._v("nil")]),t._v(", just like the default value on any Elixir struct, for single value properties. But for properties with multiple values it will be the empty list by default.")]),t._v(" "),s("p",[t._v("Generally, if a "),s("code",[t._v(":type")]),t._v(" is defined, the "),s("code",[t._v(":default")]),t._v(" value must match this datatype. Otherwise it won't compile.")]),t._v(" "),s("h2",{attrs:{id:"link-properties"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#link-properties","aria-hidden":"true"}},[t._v("#")]),t._v(" Link properties")]),t._v(" "),s("p",[t._v("Now, back to our two kinds of properties, we'll see how link properties are mapped to other Grax schemas.")]),t._v(" "),s("p",[t._v("Link properties, in the following sometimes called more shortly links, are the edges of an RDF graph between the inner nodes with URIs or blank nodes, as opposed to data properties which are the edges to leaf nodes with RDF literals. Other than for data properties, the actual value of a link property with a node identifier like an URI or a blank node is not of interest, but it's the description of the thing the identifier refers to. So, the values of link properties are not the URIs or blank nodes in the object position of an RDF statement, but another Grax schema with the properties from the RDF description of the linked resource.")]),t._v(" "),s("p",[t._v("Just like relational associations are in Ecto mapped to the struct fields through another Ecto schema for the associated table, the linked resources of a root resource are embedded into the struct in the respective field, where the properties of the linked resource are kept, potentially linking to other resources. So, the links allow us to traverse the nodes of a graph, as a tree structure down from a root resource and its fields of nested "),s("code",[t._v("Grax.Schema")]),t._v(" structs.")]),t._v(" "),s("p",[t._v("A Grax link can be defined in a Grax "),s("code",[t._v("schema")]),t._v(" definition with another macro specifically for link properties: the "),s("code",[t._v("link/3")]),t._v(" macro.\nIt has almost the same interface as the "),s("code",[t._v("property/3")]),t._v(" macro. The first two arguments are again for the name and IRI of the property.\nThe "),s("code",[t._v(":type")]),t._v(" option however has a different meaning and is no longer optional. It must be the module name of another "),s("code",[t._v("Grax.Schema")]),t._v(" struct.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":emails")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":age")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":address")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Address "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":country")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressCountry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":city")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressLocality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":street")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streetAddress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("Just like the "),s("code",[t._v("property")]),t._v(" macro, there is also a "),s("code",[t._v("link/1")]),t._v(" variant, allowing to define the link more succinctly.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("address:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("So, our "),s("code",[t._v("User")]),t._v(" struct now looks like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@example.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@work.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("address:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("Address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blank_node"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"de"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Berlin"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("While you have to deal in Ecto with the relational data model with different types of associations and mappings in the relational data model (1-to-1, 1-to-n, n-to-m, with an implicit or explicit join-schema etc.), the graph data model just has edges with different kinds of cardinalities, which are in Grax mapped to either single values or a list of multiple values, just like data properties, only that it's now just single or multiple schema structs for the linked nodes.\nJust as for data properties single linked schema structs are assumed unless it is list type is set on the  "),s("code",[t._v(":type")]),t._v(" keyword with the "),s("code",[t._v("list_of")]),t._v(" function and the module name of the schema.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":emails")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":age")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    \n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("address:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("friends:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("friend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("But as you might see already with this link property, there's one problem we'll have to solve.")]),t._v(" "),s("h3",{attrs:{id:"preloading"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#preloading","aria-hidden":"true"}},[t._v("#")]),t._v(" Preloading")]),t._v(" "),s("p",[t._v("Preloading is the operation of populating a "),s("code",[t._v("Grax.Schema")]),t._v(" struct by loading (mapping) the RDF descriptions of linked resources from an RDF graph into a tree structure over the linked property fields of a "),s("code",[t._v("Grax.Schema")]),t._v(" recursively.")]),t._v(" "),s("p",[t._v("You might have already asked yourself, how the recursive traversal of the graph for loading the nested schema of a root node is done and can be controlled.\nFor example on our "),s("code",[t._v("friends")]),t._v(" link: How many levels of friends do we want to load and how do we handle circles?")]),t._v(" "),s("p",[t._v("There are potentially several useful preloading strategies, which should be implemented in possible future versions. For now, the only preloading strategy supported is a pretty simple one, the "),s("em",[t._v("depth preloading")]),t._v(" strategy, where all of the properties and links up to a specified recursive depth are loaded.")]),t._v(" "),s("p",[t._v("The default behaviour for how deep the links of a mapping struct are loaded can be specified on a "),s("code",[t._v("link")]),t._v(" definition with the "),s("code",[t._v(":depth")]),t._v(" keyword of the depth preloading strategy and an integer for the preloading depth.\nBut before we look at a use of the "),s("code",[t._v(":depth")]),t._v(" keyword, let's see what happens if our address model would get further nested by decomposing one of its parts, eg. the country.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":address")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Address "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streetAddress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressLocality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressCountry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Country\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Country "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDFS\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GeoNames\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("code:")]),t._v(" GeoNames"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("countryCode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("The default value for "),s("code",[t._v(":depth")]),t._v(" is "),s("code",[t._v("1")]),t._v(". This means all of the data and object properties are loaded, including the nested "),s("code",[t._v("Grax.Schema")]),t._v(" mapping with the descriptions of a linked resource, BUT NOT the linked "),s("code",[t._v("Grax.Schema")]),t._v(" structs of these nested "),s("code",[t._v("Grax.Schema")]),t._v(" structs. These would only be preloaded if the depth was one more and so on. So, without a further specification of the preloading depth with the "),s("code",[t._v(":depth")]),t._v(" keyword, our "),s("code",[t._v("User")]),t._v(" struct would look like this.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@example.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@work.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("address:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("Address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" ~B"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Berlin"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wikidata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("entity"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Q183"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("When loading a "),s("code",[t._v("Grax.Schema")]),t._v(" struct the fields for the links which are not loaded just have their node identifier as a value.\nIf you've got a "),s("code",[t._v("Grax.Schema")]),t._v(" struct with "),s("code",[t._v("RDF.IRI")]),t._v("s or "),s("code",[t._v("RDF.BlankNode")]),t._v("s like this on the link field and want to access the referenced recource, you'll have to do an explicit call of the "),s("code",[t._v("Grax.preload/3")]),t._v(" function described in the next chapter about the API.")]),t._v(" "),s("p",[t._v("But to ensure a proper processing of the Grax schema structs, which might expect certain fields in deeper layers of the struct, you don't want to check for these values and have to do a manual preload. In cases like this, you can enforce the depth of the preloading with the "),s("code",[t._v(":depth")]),t._v(" keyword. This can be achieved in multiple ways.")]),t._v(" "),s("p",[t._v("The first approach might be to increase the depth on the "),s("code",[t._v("address")]),t._v(" link to 2.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":address")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("depth:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Address "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streetAddress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressLocality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressCountry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Country\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("Given respective data in a source graph our "),s("code",[t._v("User")]),t._v(" struct could now look like this:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("User1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@example.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@work.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("address:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("Address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" ~B"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Berlin"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("Country"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" ~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wikidata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("entity"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Q183"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Germany"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("code:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DE"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("But we would get this result only if the "),s("code",[t._v("User")]),t._v(" struct is the root resource.\nA normal preloading depth integer value is interpreted against the root element. This means, when loading the schema from a graph, only the specified "),s("code",[t._v(":depth")]),t._v(" of the root resource is relevant. The "),s("code",[t._v(":depth")]),t._v(" specified in the schema of a linked resource is not taken into account and doesn't increase the overall preloading depth. This can be achieved however, by specifying a preloading depth with a plus sign before the "),s("code",[t._v(":depth")]),t._v(" integer value, like "),s("code",[t._v("depth: +1")]),t._v(" . This "),s("em",[t._v("additive")]),t._v(" preloading depth will ensure that these resources are preloaded with the specified level even when the "),s("code",[t._v(":depth")]),t._v(" of the outer schema would specify otherwise.\nSo, this essentially overwrites the preloading depth specification of the parent schema.")]),t._v(" "),s("p",[t._v("Back to our example, when we generally expect that code dealing with an address in our application is interested in the properties of the country, we want to achieve that the country is always preloaded with the address, independent of whether it is preloaded as part of another resource. This can be specified with an additive preloading depth.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":address")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Address "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streetAddress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressLocality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressCountry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Country"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("depth:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("If all link properties of schema should have the same preloading depth, the "),s("code",[t._v(":depth")]),t._v(" keyword can also be specified on the "),s("code",[t._v("use Graph.Schema")]),t._v(" call.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":address")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("address"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Address\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Address "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("depth:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("street:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streetAddress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("city:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressLocality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("country:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addressCountry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Country\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("But additive preloading depths can lead to infinite preloading circles. This is prohibited by stopping with the preloading down a path, when the first already preloaded element on this path reoccurs.")]),t._v(" "),s("p",[t._v("This a pretty greedy preloading strategy. But in the first version, which is limited to working on in-memory RDF.ex graphs, where loading is quite fast and the data access doesn't require any further IO, this simple strategy gets us already quite far.")]),t._v(" "),s("h3",{attrs:{id:"inverse-property-links"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#inverse-property-links","aria-hidden":"true"}},[t._v("#")]),t._v(" Inverse property links")]),t._v(" "),s("p",[t._v("Sometimes we want to define a "),s("code",[t._v("link")]),t._v(" on a "),s("code",[t._v("Grax.Schema")]),t._v(" for which no RDF property exists directly. For example, in our data there is no property linking a user to a post directly. Instead there is the "),s("code",[t._v("schema:author")]),t._v("property which links a post to its authors, so exactly the inverse property of what we want. You can specify a link property on a "),s("code",[t._v("Grax.Schema")]),t._v(" in those cases by declaring it as an inverse property with a minus sign before the IRI of the inverse property.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    \n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("friends:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("friend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("posts:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Post"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Post "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("title:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("content:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("articleBody"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("author:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" User\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("h3",{attrs:{id:"heterogeneous-property-links"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#heterogeneous-property-links","aria-hidden":"true"}},[t._v("#")]),t._v(" Heterogeneous property links")]),t._v(" "),s("p",[t._v("Links can also link different types of resources to different schemas. For this, the "),s("code",[t._v(":type")]),t._v(" of a link property must be given as a map of class URIs to Grax schemas.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    \n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("friends:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("friend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("posts:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BlogPosting "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" Post"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Comment "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" Comment\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Comment "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("content:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("author:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" User\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("So, depending on the "),s("code",[t._v("rdf:type")]),t._v(" of the resource linked with a property the specified schema is used. When a linked resource doesn't have any of the specified types, the resource is ignored by default. You can change this behaviour and get an error in this case, by setting the "),s("code",[t._v(":on_type_mismatch")]),t._v(" option to "),s("code",[t._v(":error")]),t._v(". Another way to deal with this situation is to provide a fallback in the type-schema mapping where  "),s("code",[t._v("nil")]),t._v(" is used as the key instead of a class URI. The schema associated with "),s("code",[t._v("nil")]),t._v(" will then be used when none of the other class URI matches an "),s("code",[t._v("rdf:type")]),t._v(". When multiple classes of a linked resource are matching, you'll always get an error.")]),t._v(" "),s("h2",{attrs:{id:"cardinalities"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cardinalities","aria-hidden":"true"}},[t._v("#")]),t._v(" Cardinalities")]),t._v(" "),s("p",[t._v("You can define the cardinality the values of data properties and links of a schema must have in order to be considered valid. For non-list properties there are just two possible cardinalities: 1 or 0..1 or, in other words, required or not, which can be specified with the "),s("code",[t._v(":required")]),t._v(" option defaulting to "),s("code",[t._v("false")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("For list properties you can specify the cardinality on the "),s("code",[t._v("list")]),t._v(" resp. "),s("code",[t._v("list_of")]),t._v(" type constructor functions with the "),s("code",[t._v(":card")]),t._v(" option. It can have")]),t._v(" "),s("ul",[s("li",[t._v("a single integer value for an exact cardinality,")]),t._v(" "),s("li",[t._v("an Elixir range value (like "),s("code",[t._v("1..3")]),t._v(") for a cardinality with an lower and upper boundary,")]),t._v(" "),s("li",[t._v("or a "),s("code",[t._v("{:min, n}")]),t._v(" tuple value with an integer for a minimal cardinality without an upper boundary")])]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("card:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":min")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("{:min, 1}")]),t._v(" cardinality can be specified also by using the "),s("code",[t._v(":required")]),t._v(" option on a list type. So, this is equivalent to the former definition:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("h2",{attrs:{id:"class-declarations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#class-declarations","aria-hidden":"true"}},[t._v("#")]),t._v(" Class declarations")]),t._v(" "),s("p",[t._v("You can optionally specify that the individual "),s("code",[t._v("Grax.Schema")]),t._v(" structs representing RDF resources should be instances of an RDFS class by providing its IRI as an argument of the "),s("code",[t._v("schema")]),t._v(" macro.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("div",{staticClass:"highlight-lines"},[s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("br"),s("div",{staticClass:"highlighted"},[t._v("Â ")]),s("br"),s("br"),s("br"),s("br")]),s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  schema NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Person "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...  ")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Post "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  schema NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BlogPosting "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...  ")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Address "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  schema NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PostalAddress "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...  ")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("For now, the only effect of a class declaration is that the mapping to RDF graphs will produce a "),s("code",[t._v("rdf:type")]),t._v(" statement accordingly. In particular it doesn't mean that the RDF description of a resource must include a respective "),s("code",[t._v("rdf:type")]),t._v(" to be loadable into a "),s("code",[t._v("Grax.Schema")]),t._v(" struct.")]),t._v(" "),s("h2",{attrs:{id:"schema-inheritance"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#schema-inheritance","aria-hidden":"true"}},[t._v("#")]),t._v(" Schema inheritance")]),t._v(" "),s("p",[t._v("It is possible to derive a schema from an existing one, inheriting all of its defined properties.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Customer "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("EX\n\n  schema "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("inherit:")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("since:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("customerSince"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":date")]),t._v("\n    \n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subscription:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subscribed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Subscription\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("If a class is also declared the following form is possible:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" Customer "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("EX\n\n  schema EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Customer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("since:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("customerSince"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":date")]),t._v("\n    \n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subscription:")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subscribed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" Subscription\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("Multiple inheritance is also supported by providing the schemas in a list.")]),t._v(" "),s("p",[t._v("Note, that the class must not necessarily be a subclass of the class of the inherited schema, although this might be the case often times.")]),t._v(" "),s("p",[t._v("If some of the inherited properties should be redefined with other characteristics, this can be done without any restrictions. They can have a different type or map to a completely different RDF property, although this might be confusing.")]),t._v(" "),s("h2",{attrs:{id:"custom-fields"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#custom-fields","aria-hidden":"true"}},[t._v("#")]),t._v(" Custom fields")]),t._v(" "),s("p",[t._v("If you already have or want to define certain fields on a "),s("code",[t._v("Grax.Schema")]),t._v(" struct, which should be ignored by the RDF mapping, you can define them with the "),s("code",[t._v("field/1")]),t._v(" macro.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    \n    field "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":password")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("The default value of a custom field can be specified optionally with the "),s("code",[t._v(":default")]),t._v(" keyword.")]),t._v(" "),s("h2",{attrs:{id:"custom-mappings"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#custom-mappings","aria-hidden":"true"}},[t._v("#")]),t._v(" Custom mappings")]),t._v(" "),s("p",[t._v("Sometimes you want to perform more complex or simply non-default transformations when mapping RDF data to and from the Elixir structs of your application. In these cases you can define your own custom mapping functions on the "),s("code",[t._v("Grax.Schema")]),t._v(" module and declare their usage on the "),s("code",[t._v("property")]),t._v(" schema definition with the "),s("code",[t._v(":from_rdf")]),t._v(" and "),s("code",[t._v(":to_rdf")]),t._v(" options and the respective function names.")]),t._v(" "),s("p",[t._v("A "),s("code",[t._v("from_rdf")]),t._v(" function must accept three arguments:")]),t._v(" "),s("ol",[s("li",[t._v("The first argument is the list of the actual RDF values for the property for which the custom mapping was called.")]),t._v(" "),s("li",[t._v("The second argument is the "),s("code",[t._v("RDF.Description")]),t._v(" of the mapped resource, which can be used when the mapping depends on other properties of the resource description.")]),t._v(" "),s("li",[t._v("The third argument is whole "),s("code",[t._v("RDF.Graph")]),t._v(" from which the mapping is called, which can be used when the mapping depends on other statements of the graph.")])]),t._v(" "),s("p",[t._v("When a mapping can be performed successfully the mapped value must be returned in an "),s("code",[t._v(":ok")]),t._v(" tuple. Otherwise an "),s("code",[t._v(":error")]),t._v(" tuple with the error must be returned.")]),t._v(" "),s("p",[t._v("A "),s("code",[t._v("to_rdf")]),t._v(" function must accept two arguments:")]),t._v(" "),s("ol",[s("li",[t._v("The first argument is the list of the actual values of the property from the struct for which the custom mapping was called.")]),t._v(" "),s("li",[t._v("The second argument is the whole "),s("code",[t._v("Grax")]),t._v(" struct, which can be used when the mapping depends on other properties of it.")])]),t._v(" "),s("p",[t._v("The return value can be either:")]),t._v(" "),s("ul",[s("li",[t._v("a two-element "),s("code",[t._v(":ok")]),t._v(" tuple with the mapped RDF values")]),t._v(" "),s("li",[t._v("a three-element "),s("code",[t._v(":ok")]),t._v(" tuple with the mapped RDF values on second position and a list of additional RDF statements which should be added to the produced graph on the third position (the statements can be given in any form accepted by "),s("code",[t._v("RDF.Graph.add/2")]),t._v(")")]),t._v(" "),s("li",[t._v("an "),s("code",[t._v(":error")]),t._v(" tuple with an error")])]),t._v(" "),s("p",[t._v("For both custom mapping functions you can return "),s("code",[t._v("nil")]),t._v(" as a value when no values should be produced by the mapping.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Person "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("customer_type:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n             "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("from_rdf:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":customer_type_from_rdf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("to_rdf:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":customer_type_to_rdf")]),t._v("\n    \n    field "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":password")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("friends:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("friend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("posts:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Post"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" customer_type_from_rdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("types"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PremiumUser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" types"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":premium_user")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" customer_type_to_rdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":premium_user")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _user"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PremiumUser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" customer_type_to_rdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("Note, that if you provide both "),s("code",[t._v("from_rdf")]),t._v(" and "),s("code",[t._v("to_rdf")]),t._v(" functions, you can use any type of value on this property, even ones for which no corresponding datatype is supported.")]),t._v(" "),s("p",[t._v("Custom fields also support custom "),s("code",[t._v(":from_rdf")]),t._v(" mappings. So, if you want to define a custom mapping to a field which should not be mapped back to RDF, you can do so with a custom field.")]),t._v(" "),s("p",[t._v("The mapping functions can also be defined in a separate module by providing a tuple of the module and function name on the "),s("code",[t._v(":from_rdf")]),t._v(" and "),s("code",[t._v(":to_rdf")]),t._v(" options.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" User "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" Grax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Schema\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Person "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    \n    property "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("customer_type:")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n             "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("from_rdf:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("CustomMappings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":customer_type_from_rdf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("to_rdf:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("CustomMappings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":customer_type_to_rdf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n    field "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":password")]),t._v("\n\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("friends:")]),t._v(" FOAF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("friend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    link "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("posts:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("SchemaOrg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" list_of"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Post"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" CustomMappings "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" customer_type_from_rdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("types"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PremiumUser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" types"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":premium_user")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" customer_type_to_rdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":premium_user")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _user"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PremiumUser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" customer_type_to_rdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])])])},[],!1,null,null,null);a.default=n.exports}}]);