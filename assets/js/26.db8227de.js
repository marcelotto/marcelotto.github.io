(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{213:function(t,a,s){"use strict";s.r(a);var e=s(2),n=Object(e.a)({},function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"vocabularies"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#vocabularies","aria-hidden":"true"}},[t._v("#")]),t._v(" Vocabularies")]),t._v(" "),s("p",[t._v("RDF.ex supports modules which represent RDF vocabularies as "),s("code",[t._v("RDF.Vocabulary.Namespace")]),t._v("s. It comes with predefined modules for some fundamental vocabularies defined in the "),s("code",[t._v("RDF.NS")]),t._v(" module.")]),t._v(" "),s("p",[t._v("These "),s("code",[t._v("RDF.Vocabulary.Namespace")]),t._v("s allow for something similar to QNames in XML: an atom or function qualified with a "),s("code",[t._v("RDF.Vocabulary.Namespace")]),t._v(" can be resolved to an IRI.")]),t._v(" "),s("p",[t._v("There are two types of terms in a "),s("code",[t._v("RDF.Vocabulary.Namespace")]),t._v(" which are\nresolved differently:")]),t._v(" "),s("ol",[s("li",[t._v("Capitalized terms are by standard Elixir semantics module names, i.e.\natoms. At all places in RDF.ex where an IRI is expected, you can use atoms\nqualified with a "),s("code",[t._v("RDF.Namespace")]),t._v(" instead. If you want to resolve them\nmanually, you can pass a "),s("code",[t._v("RDF.Namespace")]),t._v(" qualified atom to "),s("code",[t._v("RDF.iri")]),t._v(".")]),t._v(" "),s("li",[t._v("Lowercased terms for RDF properties are represented as functions on a\n"),s("code",[t._v("RDF.Vocabulary.Namespace")]),t._v(" module and return the IRI directly, but since "),s("code",[t._v("RDF.iri")]),t._v(" can also handle IRIs directly, you can safely and consistently use it with lowercased terms too.")])]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("only:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Class\nRDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Class\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Class"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Class>")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subClassOf\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#subClassOf>")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDFS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subClassOf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#subClassOf>")]),t._v("\n")])])]),s("p",[t._v("As this example shows, the namespace modules can be easily "),s("code",[t._v("alias")]),t._v("ed. When required, they can be also aliased to a completely different name. Since the "),s("code",[t._v("RDF")]),t._v(" vocabulary namespace in "),s("code",[t._v("RDF.NS.RDF")]),t._v(" can't be aliased (it would clash with the top-level "),s("code",[t._v("RDF")]),t._v(" module), all of its elements can be accessed directly from the "),s("code",[t._v("RDF")]),t._v(" module (without an alias).")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("iex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("only:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1999")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("02")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("syntax"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("ns"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#type>")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1999")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("02")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("rdf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("syntax"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("ns"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Property>")]),t._v("\n")])])]),s("p",[t._v("This way of expressing IRIs has the additional benefit, that the existence of the referenced IRI is checked at compile time, i.e. whenever a term is used that is not part of the resp. vocabulary an error is raised by the Elixir compiler (unless the vocabulary namespace is non-strict; see below).")]),t._v(" "),s("p",[t._v("For terms not adhering to the capitalization rules (lowercase properties, capitalized non-properties) or containing characters not allowed within atoms, the predefined namespaces in "),s("code",[t._v("RDF.NS")]),t._v(" define aliases accordingly. If unsure, have a look at the documentation or their definitions.")]),t._v(" "),s("h2",{attrs:{id:"description-dsl"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#description-dsl","aria-hidden":"true"}},[t._v("#")]),t._v(" Description DSL")]),t._v(" "),s("p",[t._v("The functions for the properties on a vocabulary namespace module, are also available in a description builder variant, which accepts subject and objects as arguments.")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("If you want to state multiple statements with the same subject and predicate, you can either pass the objects as a list or as additional arguments, if there are not more than five of them:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Baz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nEX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("In combination with Elixirs pipe operators this leads to a description DSL resembling "),s("a",{attrs:{href:"https://www.w3.org/TR/turtle/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Turtle"),s("OutboundLink")],1),t._v(":")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("baz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The produced statements are returned by this function as a "),s("code",[t._v("RDF.Description")]),t._v(" structure which will be described below.")]),t._v(" "),s("h2",{attrs:{id:"defining-vocabulary-namespaces"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#defining-vocabulary-namespaces","aria-hidden":"true"}},[t._v("#")]),t._v(" Defining vocabulary namespaces")]),t._v(" "),s("p",[t._v("There are two basic ways to define a namespace for a vocabulary:")]),t._v(" "),s("ol",[s("li",[t._v("You can define all terms manually.")]),t._v(" "),s("li",[t._v("You can extract the terms from existing RDF data for IRIs of resources under the specified base IRI.")])]),t._v(" "),s("p",[t._v("It's recommended to introduce a dedicated module for the defined namespaces. In this module you'll "),s("code",[t._v("use RDF.Vocabulary.Namespace")]),t._v(" and define your vocabulary namespaces with the "),s("code",[t._v("defvocab")]),t._v(" macro.")]),t._v(" "),s("p",[t._v("A vocabulary namespace with manually defined terms can be defined in this way like that:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" YourApp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Vocabulary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Namespace\n\n  defvocab EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("base_iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.example.com/ns/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("terms:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("~w[Foo bar]")]),t._v("\n    \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("base_iri")]),t._v(" argument with the IRI prefix of all the terms in the defined\nvocabulary is required and expects a valid IRI ending with either a "),s("code",[t._v('"/"')]),t._v(" or\na "),s("code",[t._v('"#"')]),t._v(". Terms will be checked for invalid characters at compile-time and will raise a compiler error. This handling of invalid characters can be modified with the "),s("code",[t._v("invalid_characters")]),t._v(" options, which is set to "),s("code",[t._v(":fail")]),t._v(" by default. By setting it to "),s("code",[t._v(":warn")]),t._v(" only warnings will be raised or it can be turned off completely with "),s("code",[t._v(":ignore")]),t._v(".")]),t._v(" "),s("p",[t._v("A vocabulary namespace with extracted terms can be defined either by providing RDF data directly with the "),s("code",[t._v("data")]),t._v(" option or files with serialized RDF data in the "),s("code",[t._v("priv/vocabs")]),t._v(" directory using the "),s("code",[t._v("file")]),t._v(" option:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" YourApp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Vocabulary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Namespace\n\n  defvocab EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("base_iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.example.com/ns/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("file:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your_vocabulary.nt"')]),t._v("\n    \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("During compilation the terms will be validated and checked for proper capitalisation by analysing the schema description of the resp. resource  in the given data.\nThis validation behaviour can be modified with the "),s("code",[t._v("case_violations")]),t._v(" options, which is by default set to "),s("code",[t._v(":warn")]),t._v(". By setting it explicitly to "),s("code",[t._v(":fail")]),t._v(" errors will be raised during compilation or it can be turned off with "),s("code",[t._v(":ignore")]),t._v(".")]),t._v(" "),s("p",[t._v("Invalid characters or violations of capitalization rules can be fixed by defining aliases for these terms with the "),s("code",[t._v("alias")]),t._v(" option and a keyword list:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" YourApp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Vocabulary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Namespace\n\n  defvocab EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("base_iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.example.com/ns/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("file:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your_vocabulary.nt"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("alias:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("example_term:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"example-term"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v(":ignore")]),t._v(" option allows to ignore terms:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" YourApp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Vocabulary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Namespace\n\n  defvocab EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("base_iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.example.com/ns/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("file:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your_vocabulary.nt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ignore:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("~w[Foo bar]")]),t._v("\n    \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),s("p",[t._v("Though strongly discouraged, a vocabulary namespace can be defined as non-strict with the "),s("code",[t._v("strict")]),t._v(" option set to "),s("code",[t._v("false")]),t._v(". A non-strict vocabulary doesn't require any terms to be defined (although they can). A term is resolved dynamically at runtime by concatenation of the term and the base IRI of the resp. namespace module:")]),t._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" YourApp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Vocabulary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Namespace\n\n  defvocab EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("base_iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.example.com/ns/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("terms:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("strict:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RDF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("only:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("iri:")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" YourApp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" iri"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("ns"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bar\n~I"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("ns"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n\niex"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Foo "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Baz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#RDF.Description<")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Foo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Baz"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])])])},[],!1,null,null,null);a.default=n.exports}}]);