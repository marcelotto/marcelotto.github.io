(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{231:function(t,a,e){"use strict";e.r(a);var s=e(2),n=Object(s.a)({},function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"literals"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#literals","aria-hidden":"true"}},[t._v("#")]),t._v(" Literals")]),t._v(" "),e("p",[t._v("Literals are used for values such as strings, numbers, and dates. They can be untyped, languaged-tagged or typed (but following the RDF 1.1 spec untyped literals are in fact just "),e("code",[t._v("xsd:string")]),t._v(" typed literals)")]),t._v(" "),e("h2",{attrs:{id:"untyped-literals"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#untyped-literals","aria-hidden":"true"}},[t._v("#")]),t._v(" Untyped literals")]),t._v(" "),e("p",[t._v("In general literals are created with the "),e("code",[t._v("RDF.Literal.new")]),t._v(" constructor function or its alias function "),e("code",[t._v("RDF.literal")]),t._v(":")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("The actual value can be accessed via the "),e("code",[t._v("RDF.Literal.value/1")]),t._v(" function:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),t._v("\n")])])]),e("p",[t._v("An untyped literal can also be created with the "),e("code",[t._v("~L")]),t._v(" sigil:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sigils\n\n~L"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),t._v("\n")])])]),e("h2",{attrs:{id:"language-tagged-literals"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#language-tagged-literals","aria-hidden":"true"}},[t._v("#")]),t._v(" Language-tagged literals")]),t._v(" "),e("p",[t._v("A language-tagged literal can be created by providing the "),e("code",[t._v("language")]),t._v(" option with a "),e("a",{attrs:{href:"https://tools.ietf.org/html/bcp47",target:"_blank",rel:"noopener noreferrer"}},[t._v("BCP47"),e("OutboundLink")],1),t._v("-conform language or by adding the language as a modifier to the "),e("code",[t._v("~L")]),t._v(" sigil:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sigils\n\nRDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("language:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"en"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n~L"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),t._v("en\n")])])]),e("p",[t._v("Note: Only languages without subtags are supported as modifiers of the "),e("code",[t._v("~L")]),t._v(" sigil, i.e. if you want to use "),e("code",[t._v("en-US")]),t._v(" as a language tag, you would have to use the constructor functions.")]),t._v(" "),e("h2",{attrs:{id:"typed-literals"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#typed-literals","aria-hidden":"true"}},[t._v("#")]),t._v(" Typed literals")]),t._v(" "),e("p",[t._v("A typed literal can be created by providing the "),e("code",[t._v("datatype")]),t._v(" option with an IRI of a datatype. Most of the time this will be an "),e("a",{attrs:{href:"https://www.w3.org/TR/xmlschema11-2/",target:"_blank",rel:"noopener noreferrer"}},[t._v("XML schema datatype"),e("OutboundLink")],1),t._v(":")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NS\n\nRDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" NS"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("It is also possible to create a typed literal by using a native Elixir non-string value, for which the following datatype mapping will be applied:")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",{staticStyle:{"text-align":"left"}},[t._v("Elixir datatype")]),t._v(" "),e("th",{staticStyle:{"text-align":"left"}},[t._v("XSD datatype")])])]),t._v(" "),e("tbody",[e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("string")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:string")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("boolean")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:boolean")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("integer")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:integer")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("float")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:double")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("a",{attrs:{href:"https://github.com/ericmj/decimal",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("Decimal")]),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:decimal")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("Time")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:time")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("Date")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:date")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("DateTime")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:dateTime")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("NaiveDateTime")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:dateTime")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("URI")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:AnyURI")])])])])]),t._v(" "),e("p",[t._v("So the former example literal can be created equivalently like this:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("The "),e("code",[t._v("value/1")]),t._v(" function returns the literal value as the native Elixir value according to the above mapping. When a known XSD datatype is specified, the given value will be converted automatically if needed and possible.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" NS"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("double"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42.0")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" NS"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),t._v("\n")])])]),e("div",{staticClass:"warning custom-block"},[e("p",[t._v("For some datatypes where the value space of the XSD datatype is larger than what the corresponding Elixir datatype supports, you might also get a tuple with annotations back. For example, "),e("code",[t._v("xsd:date")]),t._v("s and "),e("code",[t._v("xsd:time")]),t._v("s support timezones while Elixir's "),e("code",[t._v("Date")]),t._v(" and "),e("code",[t._v("Time")]),t._v(" structs don't support that. In case of an "),e("code",[t._v("xsd:date")]),t._v(" with a timezone you'll get a tuple like this "),e("code",[t._v('{~D[2014-09-01], "-08:00"}')]),t._v(". For "),e("code",[t._v("xsd:time")]),t._v("s with timezones you'll instead just get a tuple like "),e("code",[t._v("{~T[23:00:00], true}")]),t._v(" with a boolean signifying that it has a timezone, since the timezone offset was already normalized in the value (the original timezone offset is kept in the lexical form).")])]),t._v(" "),e("p",[t._v("For all of the supported RDF and XSD datatypes there are "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" modules available that implement the semantics of the respective datatype.\nThey also provide a "),e("code",[t._v("new")]),t._v(" constructor function that allows the creation of "),e("code",[t._v("RDF.Literal")]),t._v("s with the respective datatype. These constructor can also be called via the alias functions on the top-level "),e("code",[t._v("RDF")]),t._v(" respective "),e("code",[t._v("RDF.XSD")]),t._v(" namespace.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we'll consider the following alias to be defined throughout this guide implicitly")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD\n\nXSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("String"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nXSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nXSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nXSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("LangString"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("language:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"en"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("langString"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("language:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"en"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Besides the "),e("code",[t._v("RDF.LangString")]),t._v(" datatype the following XSD datatypes are provided as "),e("code",[t._v("RDF.Literal.Datatype")]),t._v("s:")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",{staticStyle:{"text-align":"left"}},[t._v("XSD datatype")]),t._v(" "),e("th",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.Literal.Datatype")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:boolean")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Boolean")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:float")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Float")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:double")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Double")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:decimal")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Decimal")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:integer")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Integer")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:long")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Long")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:int")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Int")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:short")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Short")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:byte")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Byte")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:nonPositiveInteger")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.NonPositiveInteger")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:negativeInteger")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.NegativeInteger")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:nonNegativeInteger")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.NonNegativeInteger")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:positiveInteger")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.PositiveInteger")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:unsignedLong")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.UnsignedLong")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:unsignedInt")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.UnsignedInt")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:unsignedShort")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.UnsignedShort")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:unsignedByte")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.UnsignedByte")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:string")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.String")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:normalizedString")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:token")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:language")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:Name")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:NCName")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:ID")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:IDREF")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:ENTITY")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:NMTOKEN")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:dateTime")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.DateTime")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:dateTimeStamp")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:date")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Date")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:time")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Time")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:duration")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:dayTimeDuration")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:yearMonthDuration")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:gYearMonth")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:gYear")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:gMonthDay")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:gDay")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:gMonth")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:base64Binary")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:hexBinary")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:anyURI")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.AnyURI")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:QName")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("xsd:NOTATION")])]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])])])]),t._v(" "),e("p",[t._v("For literals with an unknown datatype, i.e. a datatype without a "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" module the generic "),e("code",[t._v("RDF.Literal.Generic")]),t._v(" implementation s used. For those generic literals the  "),e("code",[t._v("RDF.Literal.value/1")]),t._v(" function simply returns the initially given value unvalidated and unconverted.")]),t._v(" "),e("h2",{attrs:{id:"validation"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#validation","aria-hidden":"true"}},[t._v("#")]),t._v(" Validation")]),t._v(" "),e("p",[t._v("The "),e("code",[t._v("RDF.Literal.valid?/1")]),t._v(" function checks if a given literal is valid according to the semantics in its "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" implementation.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valid? XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valid? XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n")])])]),e("p",[t._v("Since the semantics of "),e("code",[t._v("RDF.Literal.Generic")]),t._v(" literals is unknown they are always considered to be valid.")]),t._v(" "),e("p",[t._v("If you want to prohibit the creation of invalid literals, you can use the "),e("code",[t._v("new!")]),t._v(" constructor function of the "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" or "),e("code",[t._v("RDF.Literal")]),t._v(", which will fail in case of invalid values.")]),t._v(" "),e("h2",{attrs:{id:"lexical-and-canonical-form"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#lexical-and-canonical-form","aria-hidden":"true"}},[t._v("#")]),t._v(" Lexical and canonical form")]),t._v(" "),e("p",[t._v("A RDF literal is bound to the lexical form of the initially given value. This lexical representation can be retrieved with the "),e("code",[t._v("RDF.Literal.lexical/1")]),t._v(" function:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lexical XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lexical XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),t._v("\n")])])]),e("p",[t._v("The "),e("code",[t._v("RDF.Literal.canonical/1")]),t._v(" function normalizes the given literal to the canonical lexical form according to its datatype:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("canonical "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lexical\n"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("canonical"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" \n     RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("canonical"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n")])])]),e("p",[t._v("For "),e("code",[t._v("RDF.Literal.Generic")]),t._v(" literals the "),e("code",[t._v("canonical")]),t._v(" function returns the given literal unchanged.")]),t._v(" "),e("p",[t._v("Since the canonical form is undefined for invalid literals, "),e("code",[t._v("nil")]),t._v(" is returned in this case.")]),t._v(" "),e("p",[t._v("If you're just interested in the canonical lexical form as a string you can also use the "),e("code",[t._v("RDF.Literal.canonical_lexical/1")]),t._v(" function, which is also a bit faster, since the intermediary canonicalization is not needed.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("canonical_lexical XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),t._v("\n")])])]),e("h2",{attrs:{id:"equivalence"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#equivalence","aria-hidden":"true"}},[t._v("#")]),t._v(" Equivalence")]),t._v(" "),e("p",[t._v("Although two literals might have the same value, they are not equal if they don't have the same lexical form:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n")])])]),e("p",[t._v("The "),e("code",[t._v("RDF.Literal.equal_value?/2")]),t._v(" function however, does a pure value-based equivalence comparison. It also takes into account compatibilities between different types, eg. derived datypes. Since it is the basis for the implementation of SPARQLs "),e("code",[t._v("=")]),t._v(" operator in SPARQL.ex everything that is equivalent in terms of this operator will match. Literals which aren't comparable in general due to their type and would result in an error match in terms of the SPARQL "),e("code",[t._v("=")]),t._v(" operator (meaning that also the negation wouldn't match) will return "),e("code",[t._v("nil")]),t._v(". Above this, it also coerces native Elixir values to "),e("code",[t._v("RDF.Literal")]),t._v("s before doing the comparison.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal_value?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal_value?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal_value?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("short"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("anyURI"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal_value?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iri"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0042"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal_value?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n")])])]),e("h2",{attrs:{id:"defining-custom-datatypes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#defining-custom-datatypes","aria-hidden":"true"}},[t._v("#")]),t._v(" Defining custom datatypes")]),t._v(" "),e("p",[t._v("You can define your own custom datatype by implementing the "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" behaviour. Defining a completely independent dataype however, will probably be the exception and goes beyond the scope of this introductary guide. Most of the time you want to introduce a custom datatype by constraining one of the existing XSD datatypes through datatype derivation.")]),t._v(" "),e("div",{staticClass:"danger custom-block"},[e("p",[t._v("It should be noted that a triple store won't know how to handle your custom datatype unless it's a well-known datatype he supports, so they should be introduced cautiously. But at least in the RDF.ex libraries they will behave like the predefined XSD datatypes. In particular you can apply the respective SPARQL functions within SPARQL.ex on them.")])]),t._v(" "),e("p",[t._v("So, a custom datatype can be derived from a XSD datatype (with an existing "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" implementation) by defining a new module with "),e("code",[t._v("use RDF.XSD.Datatype.Restriction")]),t._v(" and constraining its value space. RDF.ex implements most of the "),e("a",{attrs:{href:"https://www.w3.org/TR/xmlschema-2/#rf-facets",target:"_blank",rel:"noopener noreferrer"}},[t._v("XSD facets"),e("OutboundLink")],1),t._v(" as "),e("code",[t._v("RDF.XSD.Facet")]),t._v(" modules for this:")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",{staticStyle:{"text-align":"left"}},[t._v("XSD facet")]),t._v(" "),e("th",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facet")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("length")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.Length")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("minLength")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.MinLength")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("maxLength")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.MaxLength")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("maxInclusive")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.MaxInclusive")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("maxExclusive")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.MaxExclusive")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("minInclusive")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.MinInclusive")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("minExclusive")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.MinExclusive")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("totalDigits")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.TotalDigits")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("fractionDigits")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.FractionDigits")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("explicitTimezone")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.ExplicitTimezone")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("pattern")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[e("code",[t._v("RDF.XSD.Facets.Pattern")])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("whiteSpace")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("enumeration")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("assertions")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("❌")])])])]),t._v(" "),e("p",[t._v("Within the body of a module using  "),e("code",[t._v("RDF.XSD.Datatype.Restriction")]),t._v(" you can apply one or multiple of these facets with the "),e("code",[t._v("def_facet_constraint")]),t._v(" macro and specifying a value for the facets. This table shows which facets can be applied on the primitive datatypes (and their derived datatypes):")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",{staticStyle:{"text-align":"left"}},[t._v("Primitive datatype")]),t._v(" "),e("th",{staticStyle:{"text-align":"left"}},[t._v("Applicable facets")])])]),t._v(" "),e("tbody",[e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("string")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("length, maxLength, minLength, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("boolean")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("float")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("maxExclusive, maxInclusive, minExclusive, minInclusive, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("double")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("maxExclusive, maxInclusive, minExclusive, minInclusive, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("decimal")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("maxExclusive, maxInclusive, minExclusive, minInclusive, pattern, totalDigits, fractionDigits")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("integer")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("maxExclusive, maxInclusive, minExclusive, minInclusive, pattern, totalDigits")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("duration")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("maxExclusive, maxInclusive, minExclusive, minInclusive, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("dateTime")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("explicitTimezone, maxExclusive, maxInclusive, minExclusive, minInclusive, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("time")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("explicitTimezone, maxExclusive, maxInclusive, minExclusive, minInclusive, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("date")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("explicitTimezone, maxExclusive, maxInclusive, minExclusive, minInclusive, pattern")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"left"}},[t._v("anyURI")]),t._v(" "),e("td",{staticStyle:{"text-align":"left"}},[t._v("length, maxLength, minLength, pattern")])])])]),t._v(" "),e("p",[t._v("Let's see how a custom datatype for the age of a person could be defined in an application:")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" MyApp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PersonAge "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Restriction"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"person_age"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/person_age"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("base:")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NonNegativeInteger\n\n  def_facet_constraint RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Facets"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MaxInclusive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("150")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),e("p",[t._v("This datatype can now constructed by either its "),e("code",[t._v("new")]),t._v(" constructor or via the generic typed  "),e("code",[t._v("RDF.Literal")]),t._v(" constuctor and the specified datatype URI.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" MyApp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PersonAge"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("literal:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("MyApp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PersonAge"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("value:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lexical:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("valid:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/person_age"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("literal:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("MyApp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PersonAge"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("value:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lexical:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"42"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("valid:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("Within RDF.ex and the libraries on top of it (SPARQL.ex, ShEx.ex) this datatype can be used wherever a "),e("code",[t._v("xsd:nonNegativeInteger")]),t._v(" or "),e("code",[t._v("xsd:integer")]),t._v(" is expected.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal_value?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MyApp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PersonAge"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n")])])]),e("h2",{attrs:{id:"type-checking-and-reflection"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#type-checking-and-reflection","aria-hidden":"true"}},[t._v("#")]),t._v(" Type checking and reflection")]),t._v(" "),e("p",[t._v("The datatype IRI of any "),e("code",[t._v("RDF.Literal")]),t._v(" can be retrieved with the "),e("code",[t._v("RDF.Literal.datatype_id/1")]),t._v(" function.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype_id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2001")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("XMLSchema"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#integer>")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ~L"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),t._v("en "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype_id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("www"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("w3"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1999")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("02")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("rdf"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("syntax"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("ns"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#langString>")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/dt"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype_id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~I"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("dt"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),e("p",[t._v("Although you won't need this most of the time, since you can use all types of literals via the polymorphic "),e("code",[t._v("RDF.Literal")]),t._v(" functions, the inverse operation is also possible. When a "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" is defined for a datatype IRI, you can get the module dynamically by its IRI with the "),e("code",[t._v("RDF.Literal.Datatype.get/1")]),t._v(" function.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.w3.org/2001/XMLSchema#integer"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nRDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/custom/datatype"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nMy"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Custom"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming there's no custom RDF.Literal.Datatype for http://example.com/dt defined")]),t._v("\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/dt"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n")])])]),e("p",[t._v("An "),e("code",[t._v("RDF.Literal")]),t._v(" with a datatype for which a "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" is defined can be pattern matched via its "),e("code",[t._v("literal")]),t._v(" field and the module implementing the "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(".")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" fun"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("literal:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" integer_literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" fun"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("literal:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("My"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Custom"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" my_literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n")])])]),e("p",[t._v("Literals with a datatype for which no "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" is defined can be pattern matched via the "),e("code",[t._v("datatype")]),t._v(" of the "),e("code",[t._v("RDF.Literal.Generic")]),t._v(" datatype.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming there's no custom RDF.Literal.Datatype for http://example.com/dt defined")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" fun"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("literal:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Generic"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/dt"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n")])])]),e("p",[t._v("Although pattern matching is the most elegant way for type checks, this only allows for exact datatype matches. The "),e("code",[t._v("datatype?/1")]),t._v(" functions on the individual "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" modules are aware of derivations and check whether the datatype of a given literal is either the datatype for which the "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" is defined or derived of this datatype.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UnsignedInteger"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NegativeInteger"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Decimal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("TODO:")]),t._v(" ??? \n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming My.Custom.Datatype is derived from xsd:integer or one of its derived datatypes")]),t._v("\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" My"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Custom"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming there's a custom RDF.Literal.Datatype for http://example.com/dt defined and it is derived from a xsd:integer")]),t._v("\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/dt"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n")])])]),e("p",[t._v("The "),e("code",[t._v("RDF.XSD.Numeric.datatype?/1")]),t._v(" function can also be handy. It checks if the datatype of a literal is one of the numeric XSD datatypes or derived from one of them.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Numeric"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Numeric"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming My.Custom.Datatype is derived from a numeric XSD datatype")]),t._v("\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" My"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Custom"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Numeric"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming there's no custom RDF.Literal.Datatype for http://example.com/dt defined or it is not derived from a numeric XSD datatype")]),t._v("\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/dt"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Numeric"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datatype?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n")])])]),e("p",[t._v("The general purpose type check function "),e("code",[t._v("RDF.Literal.is_a?/2")]),t._v(" supports all of these "),e("code",[t._v("datatype?/1")]),t._v(" functions")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_a?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_a?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_a?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Numeric"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_a?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("langString"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("language:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"en"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_a?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Datatype"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# assuming there's no custom RDF.Literal.Datatype for http://example.com/dt")]),t._v("\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"foo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("datatype:")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://example.com/dt"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_a?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RDF"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Literal"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Generic"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n")])])]),e("p",[t._v("Most of the functions on the "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" modules are only applicable on literals of exact this datatype, but there are two notable exceptions which can be handy.")]),t._v(" "),e("p",[t._v("The "),e("code",[t._v("valid?/1")]),t._v(" function on "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" modules is able to deal with derived datatypes and returns "),e("code",[t._v("true")]),t._v(" if the given literal is valid AND of the proper type.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valid?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.14")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valid?"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n")])])]),e("p",[t._v("The "),e("code",[t._v("value/1")]),t._v(" function on the "),e("code",[t._v("RDF.Literal.Datatype")]),t._v(" modules also returns the value of literals when they are of a derived datatype (or "),e("code",[t._v("nil")]),t._v(" if the datatype is not derived from this datatype.")]),t._v(" "),e("div",{staticClass:"language-elixir extra-class"},[e("pre",{pre:!0,attrs:{class:"language-elixir"}},[e("code",[t._v("iex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byte"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),t._v("\n\niex"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.14")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|>")]),t._v(" XSD"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Integer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n")])])])])},[],!1,null,null,null);a.default=n.exports}}]);